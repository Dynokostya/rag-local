{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main file for chunking and chatGPT prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dynokostya/Documents/Projects/rag-local/data/patents\n",
      "/Users/dynokostya/Documents/Projects/rag-local/chroma_db/patents\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), 'data', 'patents')\n",
    "chroma_db_path = os.path.join(os.getcwd(), 'chroma_db', 'patents')\n",
    "if not os.path.exists(chroma_db_path):\n",
    "    os.makedirs(chroma_db_path)\n",
    "print(data_path)\n",
    "print(chroma_db_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default chunking (if semantic doesn't work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "804"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "# Select your directory\n",
    "loader = DirectoryLoader(data_path)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=150)\n",
    "documents = loader.load()\n",
    "texts = text_splitter.split_documents(documents)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error loading file /Users/dynokostya/Documents/Projects/rag-local/data/patents/lab_2_1.txt\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "failed to find libmagic.  Check your installation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Select your directory\u001b[39;00m\n\u001b[1;32m     18\u001b[0m loader \u001b[38;5;241m=\u001b[39m DirectoryLoader(data_path)\n\u001b[0;32m---> 19\u001b[0m documents \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Gradient does the best semantic chunking, alternative = 'percentile'\u001b[39;00m\n\u001b[1;32m     22\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m SemanticChunker(embeddings\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[1;32m     23\u001b[0m                                 breakpoint_threshold_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgradient\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Projects/rag-local/.venv/lib/python3.12/site-packages/langchain_community/document_loaders/directory.py:117\u001b[0m, in \u001b[0;36mDirectoryLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load documents.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/rag-local/.venv/lib/python3.12/site-packages/langchain_community/document_loaders/directory.py:195\u001b[0m, in \u001b[0;36mDirectoryLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m items:\n\u001b[0;32m--> 195\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_load_file(i, p, pbar)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pbar:\n\u001b[1;32m    198\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Documents/Projects/rag-local/.venv/lib/python3.12/site-packages/langchain_community/document_loaders/directory.py:233\u001b[0m, in \u001b[0;36mDirectoryLoader._lazy_load_file\u001b[0;34m(self, item, path, pbar)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(item)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 233\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pbar:\n",
      "File \u001b[0;32m~/Documents/Projects/rag-local/.venv/lib/python3.12/site-packages/langchain_community/document_loaders/directory.py:223\u001b[0m, in \u001b[0;36mDirectoryLoader._lazy_load_file\u001b[0;34m(self, item, path, pbar)\u001b[0m\n\u001b[1;32m    221\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_cls(\u001b[38;5;28mstr\u001b[39m(item), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_kwargs)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubdoc\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Projects/rag-local/.venv/lib/python3.12/site-packages/langchain_community/document_loaders/unstructured.py:107\u001b[0m, in \u001b[0;36mUnstructuredBaseLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlazy_load\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Document]:\n\u001b[1;32m    106\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m     elements \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_process_elements(elements)\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melements\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/Projects/rag-local/.venv/lib/python3.12/site-packages/langchain_community/document_loaders/unstructured.py:228\u001b[0m, in \u001b[0;36mUnstructuredFileLoader._get_elements\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path, Path):\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path)\n\u001b[0;32m--> 228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munstructured_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/rag-local/.venv/lib/python3.12/site-packages/unstructured/partition/auto.py:186\u001b[0m, in \u001b[0;36mpartition\u001b[0;34m(filename, content_type, file, file_filename, url, include_page_breaks, strategy, encoding, paragraph_grouper, headers, skip_infer_table_types, ssl_verify, ocr_languages, languages, detect_language_per_element, pdf_infer_table_structure, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, xml_keep_tags, data_source_metadata, metadata_filename, request_timeout, hi_res_model_name, model_name, date_from_file_object, starting_page_number, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m headers \u001b[38;5;241m!=\u001b[39m {}:\n\u001b[1;32m    182\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    183\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe headers kwarg is set but the url kwarg is not. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    184\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe headers kwarg will be ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    185\u001b[0m         )\n\u001b[0;32m--> 186\u001b[0m     file_type \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_filetype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     file\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Projects/rag-local/.venv/lib/python3.12/site-packages/unstructured/file_utils/filetype.py:102\u001b[0m, in \u001b[0;36mdetect_filetype\u001b[0;34m(file_path, file, encoding, content_type, metadata_file_path)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Determine file-type of specified file using libmagic and/or fallback methods.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03mOne of `file_path` or `file` must be specified. A `file_path` that does not\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    - Neither `file_path` nor `file` were specified.\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m ctx \u001b[38;5;241m=\u001b[39m _FileTypeDetectionContext\u001b[38;5;241m.\u001b[39mnew(\n\u001b[1;32m     96\u001b[0m     file_path\u001b[38;5;241m=\u001b[39mfile_path,\n\u001b[1;32m     97\u001b[0m     file\u001b[38;5;241m=\u001b[39mfile,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m     metadata_file_path\u001b[38;5;241m=\u001b[39mmetadata_file_path,\n\u001b[1;32m    101\u001b[0m )\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_FileTypeDetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/rag-local/.venv/lib/python3.12/site-packages/unstructured/file_utils/filetype.py:135\u001b[0m, in \u001b[0;36m_FileTypeDetector.file_type\u001b[0;34m(cls, ctx)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfile_type\u001b[39m(\u001b[38;5;28mcls\u001b[39m, ctx: _FileTypeDetectionContext) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FileType:\n\u001b[1;32m    134\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Detect file-type of document-source described by `ctx`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file_type\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/rag-local/.venv/lib/python3.12/site-packages/unstructured/file_utils/filetype.py:145\u001b[0m, in \u001b[0;36m_FileTypeDetector._file_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file_type\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# -- strategy 2: guess MIME-type using libmagic and use that --\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_type \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file_type_from_guessed_mime_type\u001b[49m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file_type\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# -- strategy 3: use filename-extension, like \".docx\" -> FileType.DOCX --\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Projects/rag-local/.venv/lib/python3.12/site-packages/unstructured/file_utils/filetype.py:185\u001b[0m, in \u001b[0;36m_FileTypeDetector._file_type_from_guessed_mime_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_file_type_from_guessed_mime_type\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FileType \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"FileType based on auto-detection of MIME-type by libmagic.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    In some cases refinements are necessary on the magic-derived MIME-types. This process\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m    includes applying those rules, most of which are accumulated through practical experience.\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     mime_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmime_type\u001b[49m\n\u001b[1;32m    186\u001b[0m     extension \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ctx\u001b[38;5;241m.\u001b[39mextension\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;66;03m# -- when libmagic is not installed, the `filetype` package is used instead.\u001b[39;00m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;66;03m# -- `filetype.guess()` returns `None` for file-types it does not support, which\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;66;03m# -- unfortunately includes all the textual file-types like CSV, EML, HTML, MD, RST, RTF,\u001b[39;00m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;66;03m# -- TSV, and TXT. When we have no guessed MIME-type, this strategy is not applicable.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Projects/rag-local/.venv/lib/python3.12/site-packages/unstructured/utils.py:155\u001b[0m, in \u001b[0;36mlazyproperty.__get__\u001b[0;34m(self, obj, type)\u001b[0m\n\u001b[1;32m    150\u001b[0m value \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# --- on first access, the __dict__ item will be absent. Evaluate fget()\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# --- and store that value in the (otherwise unused) host-object\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# --- __dict__ value of same name ('fget' nominally)\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(_T, value)\n",
      "File \u001b[0;32m~/Documents/Projects/rag-local/.venv/lib/python3.12/site-packages/unstructured/file_utils/filetype.py:366\u001b[0m, in \u001b[0;36m_FileTypeDetectionContext.mime_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    363\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LIBMAGIC_AVAILABLE:\n\u001b[0;32m--> 366\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmagic\u001b[39;00m\n\u001b[1;32m    368\u001b[0m     mime_type \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    369\u001b[0m         magic\u001b[38;5;241m.\u001b[39mfrom_file(file_path, mime\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m file_path\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m magic\u001b[38;5;241m.\u001b[39mfrom_buffer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_head, mime\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    372\u001b[0m     )\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mime_type\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mif\u001b[39;00m mime_type \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Projects/rag-local/.venv/lib/python3.12/site-packages/magic/__init__.py:209\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m m\u001b[38;5;241m.\u001b[39mfrom_descriptor(fd)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loader\n\u001b[0;32m--> 209\u001b[0m libmagic \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m magic_t \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_void_p\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merrorcheck_null\u001b[39m(result, func, args):\n",
      "File \u001b[0;32m~/Documents/Projects/rag-local/.venv/lib/python3.12/site-packages/magic/loader.py:49\u001b[0m, in \u001b[0;36mload_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m   \u001b[38;5;66;03m# It is better to raise an ImportError since we are importing magic module\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed to find libmagic.  Check your installation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: failed to find libmagic.  Check your installation"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from config import azure_openai_key, azure_openai_endpoint, azure_openai_api_version, azure_openai_embedding_deployment\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = azure_openai_key\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = azure_openai_endpoint\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = azure_openai_api_version\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    deployment=azure_openai_embedding_deployment,\n",
    "    chunk_size=1024\n",
    ")\n",
    "\n",
    "# Select your directory\n",
    "loader = DirectoryLoader(data_path)\n",
    "documents = loader.load()\n",
    "\n",
    "# Gradient does the best semantic chunking, alternative = 'percentile'\n",
    "text_splitter = SemanticChunker(embeddings=embeddings,\n",
    "                                breakpoint_threshold_type='gradient')\n",
    "\n",
    "chunks = text_splitter.create_documents([documents[i].page_content for i in range(len(documents))])\n",
    "\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings and save to folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chunks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(persist_directory)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# vectorstore = Chroma.from_documents(texts, embeddings, persist_directory=persist_directory)\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m Chroma\u001b[38;5;241m.\u001b[39mfrom_documents(\u001b[43mchunks\u001b[49m, embeddings, persist_directory\u001b[38;5;241m=\u001b[39mpersist_directory)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# db = Chroma()\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# db.from_documents\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chunks' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "from config import azure_openai_embedding_deployment\n",
    "from langchain_chroma import Chroma\n",
    "from config import azure_openai_key, azure_openai_endpoint, azure_openai_api_version\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = azure_openai_key\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = azure_openai_endpoint\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = azure_openai_api_version\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    deployment=azure_openai_embedding_deployment,\n",
    "    chunk_size=1024\n",
    ")\n",
    "\n",
    "if not os.path.exists(chroma_db_path):\n",
    "    os.makedirs(chroma_db_path)\n",
    "\n",
    "vectorstore = Chroma.from_documents(chunks, embeddings, persist_directory=chroma_db_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-4o model usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt for сталий розвиток"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "System:\n",
    "```\n",
    "You are a search assistant.\n",
    "You are an expert in \"Consistent evolvement\".\n",
    "You will be asked a question.\n",
    "Question may contain multiple answers.\n",
    "Provide the full text from the retrieved documents that supports your answer.\n",
    "\n",
    "All information will be provided in Ukrainian language.\n",
    "Answer in Ukrainian language.\n",
    "\n",
    "You should not use any external resources or make up information, but \n",
    "if you cannot find context for the answer, say \n",
    "\"У контексті не було надано інфморації, шукаю по зовнішнім ресурсам\" and use your knowledge and external recources.\n",
    "\n",
    "You should think step by step and give every though.\n",
    "When you wrote 10 words in 1 line, you should start a new line.\n",
    "Every line should contain no more than 10 words.\n",
    "Example:\n",
    "```\n",
    "---Відповідь---\n",
    "...\n",
    "---Пояснення---\n",
    "...\n",
    "---Думки---\n",
    "...\n",
    "```\n",
    "\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt for patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Відповідь---\n",
      "У контексті не було надано інформації, шукаю по зовнішнім ресурсам.\n",
      "\n",
      "---Пояснення---\n",
      "В наданих документах не міститься інформації щодо \"Consistent evolvement\" \n",
      "або \"послідовного розвитку\". \n",
      "\n",
      "---Думки---\n",
      "1. Перевірив наданий контекст.\n",
      "2. Не знайшов згадки про \"Consistent evolvement\".\n",
      "3. Переходжу до використання зовнішніх ресурсів.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from config import azure_openai_gpt_deployment, azure_openai_api_version\n",
    "\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    deployment=azure_openai_embedding_deployment,\n",
    "    chunk_size=1024\n",
    ")\n",
    "\n",
    "vectorstore = Chroma(persist_directory=chroma_db_path, embedding_function=embeddings)\n",
    "\n",
    "gpt = AzureChatOpenAI(\n",
    "    deployment_name=azure_openai_gpt_deployment,\n",
    "    api_version=azure_openai_api_version\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=gpt,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 5}),\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "user = \"\"\"\n",
    "User:\n",
    "```\n",
    "\n",
    "```\n",
    "\"\"\"\n",
    "query = prompt + user + \"\\nAnswer:\"\n",
    "answer = qa_chain.invoke({\"query\": query})\n",
    "print(answer.get(\"result\"))\n",
    "#print()\n",
    "#answer.get(\"source_documents\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
